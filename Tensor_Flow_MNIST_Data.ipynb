{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Multi-Layer Perceptron\n",
    "\n",
    "Multi Layer Perceptron model to try to classify hand written digits using TensorFlow.\n",
    "\n",
    "MNIST data set of [handwritten digits](http://yann.lecun.com/exdb/mnist/). \n",
    "\n",
    "The images are black and white images of size 28 x 28 pixels, or 784 pixels total. Features will be the pixel values for each pixel. Either the pixel is \"white\" (blank with a 0), or there is some pixel value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "# Numpy is the fundamental package for scientific computing with Python\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib is used for graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline is magic command. This performs the necessary behind-the-scenes setup for IPython to work correctly hand in hand with matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Library to import MNIST Data\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "mnist=input_data.read_data_sets('/tmp/data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To see our data\n",
    "sample=mnist.train.images[1022].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b832eee8d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b8330f50b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample,cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# Learning Rate - How quickly to adjust the cost function.\n",
    "# Training Epochs - How many training cycles to go through\n",
    "# Batch Size - Size of the 'batches' of training data\n",
    "\n",
    "learning_rate =0.01\n",
    "training_epochs =15\n",
    "batch_size =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : Place Holder for Data Input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dicitionary of biases\n",
    "    '''\n",
    "    \n",
    "    # First Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=tf.placeholder('float',[None,n_input])\n",
    "y=tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost =tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=mnist.train.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsamp,ysamp = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch: 1 cost=47.2376\n",
      "Epoch: 2 cost=8.5407\n",
      "Epoch: 3 cost=4.7683\n",
      "Epoch: 4 cost=3.2909\n",
      "Epoch: 5 cost=2.6277\n",
      "Epoch: 6 cost=2.4564\n",
      "Epoch: 7 cost=1.9550\n",
      "Epoch: 8 cost=1.7337\n",
      "Epoch: 9 cost=1.5574\n",
      "Epoch: 10 cost=1.4798\n",
      "Epoch: 11 cost=1.2893\n",
      "Epoch: 12 cost=1.0913\n",
      "Epoch: 13 cost=0.9235\n",
      "Epoch: 14 cost=1.0144\n",
      "Epoch: 15 cost=0.8712\n",
      "Model has completed 15 Epochs of Training\n"
     ]
    }
   ],
   "source": [
    "# Launch the session\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.initialize_all_variables()\n",
    "# Intialize all the variables\n",
    "sess.run(init)\n",
    "\n",
    "# Training Epochs\n",
    "# Essentially the max amount of loops possible before we stop\n",
    "# May stop earlier if cost/loss limit was set\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    # Start with cost = 0.0\n",
    "    avg_cost = 0.0\n",
    "\n",
    "    # Convert total number of batches to integer\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "\n",
    "        # Grab the next batch of training data and labels\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # Feed dictionary for optimization and loss value\n",
    "        # Returns a tuple, but we only need 'c' the cost\n",
    "        # So we set an underscore as a \"throwaway\"\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"Epoch: {} cost={:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of Training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.963\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
